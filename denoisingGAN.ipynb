{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = x_train[1]\n",
    "test_image = test_image / 255\n",
    "show_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(img)\n",
    " \n",
    "show_image(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test_image = Image.open('test_img.jpg')\n",
    "test_image = np.array(test_image)\n",
    "test_image = test_image / 255\n",
    "show_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_gaussian_noise(img, simga):\n",
    "    noise = np.random.normal(0, simga, img.shape)\n",
    "    return np.clip(img + noise, 0, 1)\n",
    "\n",
    "def apply_salt_and_pepper_noise(img, prob):\n",
    "    s_and_p = np.random.rand(*img.shape)\n",
    "    new_img = img.copy()\n",
    "    new_img[s_and_p < prob] = 0\n",
    "    new_img[s_and_p > 1 - prob] = 1\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_gaussian_noise(test_image, 0.07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_salt_and_pepper_noise(test_image, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, 0.05, (3, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = skimage.util.random_noise(test_image, var=0.25**2)\n",
    "show_image(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = skimage.util.random_noise(test_image, mode='poisson')\n",
    "show_image(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = skimage.util.random_noise(test_image, mode='s&p')\n",
    "show_image(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_train, x_test), axis=0)\n",
    "x = x / 255\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_with_noise(y, modes, mode_partition=None):\n",
    "    if mode_partition:\n",
    "        if len(mode_partition) != len(modes):\n",
    "            raise ValueError('Number of partitions should match number of modes')\n",
    "        if sum(mode_partition) > len(y):\n",
    "            raise ValueError('Total partitions ' + sum(mode_partition) + ' > number of images ' + len(y))\n",
    "    else:\n",
    "        mode_partition = [len(y) // len(modes)] * len(modes)\n",
    "        \n",
    "    x = []\n",
    "    for partition in mode_partition:\n",
    "        i = 0 \n",
    "        for image in y[i:partition+i]:\n",
    "            x.append(skimage.util.random_noise(test_image, mode='s&p'))\n",
    "        i += partitio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, _), (x_test, _) = cifar10.load_data()\n",
    "    y = np.concatenate((x_train, x_test), axis=0)\n",
    "    return y\n",
    "\n",
    "def preprocess_data(x):\n",
    "    x = x / 255\n",
    "    return x\n",
    "\n",
    "def generate_images_with_gaussian_noise(y, sigma=0.1):\n",
    "    x = []\n",
    "    for img in y:\n",
    "        x.append(skimage.util.random_noise(img, var=sigma**2, mode='gaussian'))\n",
    "    return np.array(x)\n",
    "\n",
    "def generate_images_with_poisson_noise(y):\n",
    "    x = []\n",
    "    for img in y:\n",
    "        x.append(skimage.util.random_noise(img, mode='poisson'))\n",
    "    return np.array(x)\n",
    "\n",
    "def generate_images_with_s_and_p_noise(y, amount=0.05, salt_vs_pepper=0.5):\n",
    "    x = []\n",
    "    for img in y:\n",
    "        x.append(skimage.util.random_noise(img, mode='s&p', amount=amount,\n",
    "                                           salt_vs_pepper=salt_vs_pepper))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = preprocess_data(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_images_with_gaussian_noise(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, UpSampling2D, Dropout, Input, Flatten\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, x, y):\n",
    "        self.input_shape = x[0].shape\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.generator = self._get_generator()\n",
    "        self.discriminator = self._get_discriminator()\n",
    "        self.gan = self._get_gan(self.generator, self.discriminator)\n",
    "        \n",
    "    def _get_generator(self):\n",
    "        generator = Sequential()\n",
    "        generator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                             input_shape=self.input_shape,\n",
    "                             activation='relu', padding='same'))\n",
    "        #generator.add(Dropout(0.25))\n",
    "        #generator.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        #generator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "        #                     activation='relu', padding='same'))\n",
    "        #generator.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "        \n",
    "        generator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                             activation='relu', padding='same'))\n",
    "        #generator.add(UpSampling2D((2, 2)))\n",
    "        #generator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "        #                     activation='relu', padding='same'))\n",
    "        #generator.add(UpSampling2D((2, 2)))\n",
    "        generator.add(Conv2D(filters=3, kernel_size=(3, 3),\n",
    "                             activation='sigmoid', padding='same'))\n",
    "        generator.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "        return generator\n",
    "    \n",
    "    def _get_discriminator(self):\n",
    "        discriminator = Sequential()\n",
    "        discriminator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                             input_shape=self.input_shape,\n",
    "                             activation='relu'))\n",
    "        discriminator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                             activation='relu'))\n",
    "        discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        discriminator.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                             activation='relu'))\n",
    "        discriminator.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        discriminator.add(Dropout(0.25))\n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dense(512, activation='relu'))\n",
    "        discriminator.add(Dropout(0.5))\n",
    "        discriminator.add(Dense(1, activation='sigmoid'))\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return discriminator\n",
    "        \n",
    "    def _get_gan(self, generator, discriminator):\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        gan_input = Input(shape=self.input_shape)\n",
    "        x = generator(gan_input)\n",
    "        gan_output = discriminator(x)\n",
    "        gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "        gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return gan\n",
    "    \n",
    "    def train(self, epochs, batch_size=128):\n",
    "        accuracy = 0.5\n",
    "        \n",
    "        for e in range(1, epochs+1):\n",
    "            print('-'*10, 'Epoch %s' % e, '-'*10)\n",
    "            \n",
    "            batch = np.random.randint(0, self.x.shape[0], size=batch_size)\n",
    "            image_noise_batch = self.x[batch]\n",
    "            image_batch = self.y[batch]\n",
    "            \n",
    "            generated = self.generator.predict(image_noise_batch)\n",
    "            X = np.concatenate([image_batch, generated])\n",
    "            \n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size] = 1\n",
    "            \n",
    "            self.discriminator.trainable = True\n",
    "            self.generator.trainable = False\n",
    "            \n",
    "            accuracy = 0.5\n",
    "            while accuracy < 0.9:\n",
    "                disc_loss, accuracy = self.discriminator.train_on_batch(X, y_dis)\n",
    "                print('Discriminator accuracy:', accuracy)\n",
    "                \n",
    "            y_gen = np.ones(batch_size)\n",
    "            self.discriminator.trainable = False\n",
    "            self.generator.trainable = True\n",
    "            gan_accuracy = 0\n",
    "            while gan_accuracy < 0.6:\n",
    "                gan_loss, gan_accuracy = self.gan.train_on_batch(image_noise_batch, y_gen)\n",
    "                print('GAN accuracy:', gan_accuracy)\n",
    "            \n",
    "            print('Discriminator loss:', disc_loss, \n",
    "                  'Discriminator accuracy:', accuracy,\n",
    "                  'GAN loss:', gan_loss,\n",
    "                  'GAN accuracy:', gan_accuracy)\n",
    "            \n",
    "            if e == 1 or e % 5 == 0:\n",
    "                self.plot_images(e)\n",
    "            \n",
    "    def plot_images(self, epoch):\n",
    "        image_noise_batch = self.x[np.random.randint(0, self.x.shape[0], size=2)]\n",
    "        generated_images = self.generator.predict(image_noise_batch)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "        \n",
    "        ax[0][0].imshow(image_noise_batch[0])\n",
    "        ax[0][1].imshow(generated_images[0])\n",
    "        ax[1][0].imshow(image_noise_batch[1])\n",
    "        ax[1][1].imshow(generated_images[1])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сделать grayscale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
